import os
import re
from datetime import datetime  # [ìˆ˜ì • 1] datetime ëª¨ë“ˆ ì¶”ê°€
from PIL import Image, ImageFont, ImageDraw
if not hasattr(Image, 'ANTIALIAS'): Image.ANTIALIAS = Image.LANCZOS
from moviepy.editor import *
import moviepy.video.fx.all as vfx # [ìˆ˜ì • 2] vfx ëª…ì‹œì  ì„í¬íŠ¸
import numpy as np
import textwrap

# [ì„¤ì •] í°íŠ¸ ê²½ë¡œ (Windows ê¸°ì¤€) - ì—†ìœ¼ë©´ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
# Roboto-Bold.ttf íŒŒì¼ì„ í”„ë¡œì íŠ¸ í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”
FONT_PATH = "Roboto-Bold.ttf" 

# [ì„¤ì •] ë ˆì´ì•„ì›ƒ (1920x1080 ê¸°ì¤€)
W, H = 1920, 1080
SUBTITLE_Y = 900  # ìë§‰ ìœ„ì¹˜ (í•˜ë‹¨)
FONT_SIZE = 65    # ìë§‰ í¬ê¸°

class EditorLong:
    def __init__(self):
        os.makedirs("results", exist_ok=True)
        try:
            self.font = ImageFont.truetype(FONT_PATH, FONT_SIZE)
        except:
            print("âš ï¸ Custom font not found. Using default.")
            self.font = ImageFont.load_default()

    def clean_text(self, text):
        if not text: return ""
        # íŠ¹ìˆ˜ë¬¸ì ì œê±°í•˜ë˜, ê°•ì¡° í‘œì‹œ(*)ëŠ” ë‚¨ê¹€
        pattern = r'[^a-zA-Z0-9\s.,?!:;\'"*\-()\[\]%ê°€-í£]'
        return re.sub(pattern, '', text).strip()

    def create_subtitle_image(self, text, width=1600):
        """
        íˆ¬ëª… ë°°ê²½ì— ìë§‰ì„ ê·¸ë¦¬ëŠ” í•¨ìˆ˜ (í•˜ì´ë¼ì´íŠ¸ í¬í•¨)
        """
        # 1. í…ìŠ¤íŠ¸ ì¤„ë°”ê¿ˆ (í™”ë©´ ë„ˆë¹„ì— ë§ê²Œ)
        wrapper = textwrap.TextWrapper(width=50) # ì•½ 50ì ë§ˆë‹¤ ì¤„ë°”ê¿ˆ
        lines = wrapper.wrap(text)
        if len(lines) > 2: lines = lines[:2] # ìµœëŒ€ 2ì¤„ ì œí•œ

        # 2. ìº”ë²„ìŠ¤ ì¤€ë¹„
        line_height = int(FONT_SIZE * 1.4)
        total_height = line_height * len(lines)
        img = Image.new('RGBA', (W, total_height + 20), (0, 0, 0, 0))
        draw = ImageDraw.Draw(img)

        # 3. í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸° (ì¤‘ì•™ ì •ë ¬)
        y = 0
        for line in lines:
            # *ë³„í‘œ* íŒŒì‹± (í•˜ì´ë¼ì´íŠ¸ ë¡œì§)
            clean_line = self.clean_text(line)
            parts = []
            buffer = ""; is_highlight = False
            for char in clean_line:
                if char == '*':
                    if buffer: parts.append((buffer, is_highlight))
                    buffer = ""; is_highlight = not is_highlight
                else: buffer += char
            if buffer: parts.append((buffer, is_highlight))

            # ë¼ì¸ ì „ì²´ ë„ˆë¹„ ê³„ì‚° (ì¤‘ì•™ ì •ë ¬ìš©)
            total_w = sum([self.font.getlength(p[0]) for p in parts])
            current_x = (W - total_w) / 2

            # ê²€ì€ìƒ‰ ì™¸ê³½ì„ (Stroke) + í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
            for part_text, highlight in parts:
                fill_color = '#FFFF00' if highlight else 'white'
                # ì™¸ê³½ì„  (ê°€ë…ì„± í™•ë³´)
                stroke_width = 4
                for dx in range(-stroke_width, stroke_width+1):
                    for dy in range(-stroke_width, stroke_width+1):
                        draw.text((current_x+dx, y+dy), part_text, font=self.font, fill='black')
                # ë³¸ë¬¸
                draw.text((current_x, y), part_text, font=self.font, fill=fill_color)
                current_x += self.font.getlength(part_text)
            
            y += line_height

        return img

    def create_scene_clip(self, idx, scene_data, audio_path):
        """
        í•˜ë‚˜ì˜ ì”¬(ì˜¤ë””ì˜¤+ë¹„ì£¼ì–¼+ìë§‰)ì„ ë§Œë“œëŠ” í•¨ìˆ˜
        """
        # 1. ì˜¤ë””ì˜¤ ë¡œë“œ
        if not os.path.exists(audio_path): return None
        audio = AudioFileClip(audio_path)
        duration = audio.duration + 0.5 # 0.5ì´ˆ ì—¬ìœ 

        # 2. ë¹„ì£¼ì–¼ ë¡œë“œ (ì´ë¯¸ì§€ vs ë¹„ë””ì˜¤)
        visual_type = scene_data.get('visual_type', 'image')
        img_path = f"images/image_{idx}.png"
        vid_path = f"videos/video_{idx}.mp4"
        
        visual_clip = None

        # [Case A] ë¹„ë””ì˜¤ (Pexels)
        if visual_type == 'video' and os.path.exists(vid_path):
            try:
                # ë¹„ë””ì˜¤ ë¡œë“œ
                v = VideoFileClip(vid_path)
                
                # [ìˆ˜ì • 2] vfx ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ë£¨í”„ ì²˜ë¦¬
                if v.duration < duration:
                    v = vfx.loop(v, duration=duration)
                else:
                    v = v.subclip(0, duration)
                
                # 1920x1080ì— ë§ì¶° Crop & Resize
                visual_clip = v.resize(height=H) # ë†’ì´ ê¸°ì¤€ ë§ì¶¤
                if visual_clip.w < W: 
                    visual_clip = v.resize(width=W) # ë„ˆë¹„ ê¸°ì¤€ ë§ì¶¤
                visual_clip = visual_clip.crop(x1=visual_clip.w/2 - W/2, y1=0, width=W, height=H)
                
            except Exception as e:
                print(f"      âš ï¸ Video Load Error: {e}. Fallback to Image.")
                visual_type = 'image'

        # [Case B] ì´ë¯¸ì§€ (Zoom Effect)
        if visual_type == 'image' or visual_clip is None:
            if not os.path.exists(img_path):
                # ì´ë¯¸ì§€ë„ ì—†ìœ¼ë©´ ë¸”ë™ ìŠ¤í¬ë¦°
                return ColorClip(size=(W, H), color=(0,0,0)).set_duration(duration).set_audio(audio)
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            pil_img = Image.open(img_path).convert("RGB")
            
            # 1920x1080 ë¹„ìœ¨(16:9)ë¡œ í¬ë¡­
            iw, ih = pil_img.size
            target_ratio = W / H
            if iw / ih > target_ratio: # ì´ë¯¸ì§€ê°€ ë” ë„“ìŒ -> ì–‘ì˜† ìë¦„
                new_w = int(ih * target_ratio)
                pil_img = pil_img.crop(((iw - new_w)//2, 0, (iw - new_w)//2 + new_w, ih))
            else: # ì´ë¯¸ì§€ê°€ ë” ê¸¸ì­‰í•¨ -> ìœ„ì•„ë˜ ìë¦„
                new_h = int(iw / target_ratio)
                pil_img = pil_img.crop((0, (ih - new_h)//2, iw, (ih - new_h)//2 + new_h))
            
            pil_img = pil_img.resize((W, H), Image.LANCZOS)
            
            # Zoom Effect (Ken Burns)
            clip = ImageClip(np.array(pil_img)).set_duration(duration)
            visual_clip = clip.resize(lambda t: 1 + 0.04 * t)  # 4% ì¤Œì¸
            # ì¤‘ì•™ ì •ë ¬ (ì¤Œì¸ ì‹œ ìœ„ì¹˜ ë³´ì •)
            visual_clip = visual_clip.set_position('center')

        # 3. ìë§‰ ì˜¤ë²„ë ˆì´
        narration = scene_data.get('narration', '')
        sub_img = self.create_subtitle_image(narration)
        sub_clip = ImageClip(np.array(sub_img)).set_duration(duration)
        sub_clip = sub_clip.set_position(('center', SUBTITLE_Y))

        # 4. ìµœì¢… í•©ì„± (ë¹„ì£¼ì–¼ + ìë§‰)
        final_clip = CompositeVideoClip([visual_clip, sub_clip], size=(W, H))
        final_clip = final_clip.set_audio(audio)
        
        return final_clip

    def make_video(self, data):
        print(f"ğŸ¬ [Editor] Assembling Long-Form Video...")
        scenes = data['script']['scenes']
        clips = []
        
        # 1. Intro (ìˆìœ¼ë©´ ì²˜ë¦¬)
        if os.path.exists("audio/intro.mp3"):
            # ì¸íŠ¸ë¡œëŠ” ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë‚˜ ë¹„ë””ì˜¤ë¥¼ ë°°ê²½ìœ¼ë¡œ ì‚¬ìš©
            intro_scene = {"visual_type": "image", "narration": data.get("intro_narration", "")}
            # ì²« ë²ˆì§¸ ì”¬ì˜ ë¦¬ì†ŒìŠ¤ë¥¼ ë¹Œë ¤ì˜´
            if os.path.exists("videos/video_1.mp4"): intro_scene["visual_type"] = "video"
            
            intro_clip = self.create_scene_clip(1, intro_scene, "audio/intro.mp3")
            if intro_clip: clips.append(intro_clip)

        # 2. Main Scenes
        for i, scene in enumerate(scenes):
            idx = i + 1
            audio_path = f"audio/audio_{idx}.mp3"
            clip = self.create_scene_clip(idx, scene, audio_path)
            if clip:
                clips.append(clip)
                print(f"   âœ… Processed Scene {idx}/{len(scenes)}")

        # 3. Outro (ìˆìœ¼ë©´ ì²˜ë¦¬)
        if os.path.exists("audio/outro.mp3"):
            outro_scene = {"visual_type": "image", "narration": data.get("outro_narration", "")}
            # ë§ˆì§€ë§‰ ì”¬ ë¦¬ì†ŒìŠ¤ í™œìš©
            last_idx = len(scenes)
            if os.path.exists(f"videos/video_{last_idx}.mp4"): 
                outro_scene["visual_type"] = "video"
            
            outro_clip = self.create_scene_clip(last_idx, outro_scene, "audio/outro.mp3")
            if outro_clip: clips.append(outro_clip)

        if not clips:
            print("âŒ No clips created.")
            return None

        # 4. ë Œë”ë§
        final_video = concatenate_videoclips(clips, method="compose")
        
        # ë°°ê²½ìŒì•… (ì˜µì…˜: assets/bgm.mp3ê°€ ìˆë‹¤ë©´ ì¶”ê°€)
        if os.path.exists("assets/bgm.mp3"):
            from moviepy.audio.fx import volumex
            bgm = AudioFileClip("assets/bgm.mp3").loop(duration=final_video.duration)
            bgm = bgm.fx(volumex, 0.1) # ë³¼ë¥¨ 10%
            final_audio = CompositeAudioClip([bgm, final_video.audio])
            final_video = final_video.set_audio(final_audio)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M")
        output_filename = f"results/longform_{timestamp}.mp4"
        
        print(f"ğŸš€ Rendering Final Video: {output_filename}")
        # YouTube ê¶Œì¥: 1080p, 30fps, High Bitrate
        final_video.write_videofile(
            output_filename, 
            fps=30, 
            codec="libx264", 
            audio_codec="aac", 
            bitrate="8000k", 
            preset="medium"
        )
        
        return output_filename